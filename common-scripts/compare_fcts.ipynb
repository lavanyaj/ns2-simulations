{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.use(\"TkAgg\")\n",
    "result_dirs=[\"../%s-scripts/files_to_run/results\"%(scheme) for scheme in [\"sperc\", \"rcp\", \"pfabric\"]]\n",
    "result_dirs.append(\"../../waterfilling/output_from_ideal-144\")\n",
    "\n",
    "import os\n",
    "def get_fct_files(result_dirs):\n",
    "    fct_files = []\n",
    "    for result_dir in result_dirs:\n",
    "        for dirpath, _, files in os.walk(result_dir):\n",
    "            for f in files:\n",
    "                if f.endswith(\"flow.tr\"):\n",
    "                    fct_files.append(\"%s/%s\"%(dirpath, f))\n",
    "    return fct_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fct_files = get_fct_files(result_dirs)\n",
    "print(\"%d files found: %s\" % (len(fct_files), str(fct_files[:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this cell when there is a change in the convention for naming files\n",
    "def get_config(filename):\n",
    "    \"\"\"\n",
    "    Returns cdf, load, topo, servers, scheme1, kw, date\n",
    "     or None if there was an error parsing the filename.\n",
    "    \"\"\"\n",
    "    c = {}\n",
    "    config_match=re.match(\".*/cdf(.*)_load(.*)_topo(.*)_(.*)_(.*)_(.*)_(.*).flow.tr\", filename)\n",
    "    if config_match:    \n",
    "        c[\"cdf\"], c[\"load\"], c[\"topo\"], c[\"servers\"], c[\"scheme\"], c[\"kw\"], c[\"date\"] = config_match.groups()\n",
    "    return c\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this cell to change appearance of plots\n",
    "\n",
    "fontsize = 12\n",
    "styles = {} # scheme: {kw: [line_label, style, color, alpha]}\n",
    "styles[\"sperc\"] = {\n",
    "    \"wt1-pri2-match-ign\": [\"s-PERC (basic)\", \"solid\", \"green\", 0.9],\n",
    "    \"wt1-pri2-match-start100-short-ign\": [\"s-PERC (short)\", \"solid\", \"blue\", 0.9]}\n",
    "styles[\"rcp\"] = {\"a0.4b0.2\": [\"RCP\", \"dashed\", \"red\", 0.9]}\n",
    "styles[\"pfabric\"] = {\"basic\": [\"p-Fabric\", \"-.\", \"orange\", 0.9]}\n",
    "styles[\"waterfilling\"] = {\"ideal-maxmin\": [\"Ideal\", \"dotted\", \"black\", 0.9]}\n",
    "\n",
    "schemes_in_order = [(\"pfabric\", \"basic\"), \n",
    "                    (\"rcp\", \"a0.4b0.2\"),\n",
    "                    (\"sperc\", \"wt1-pri2-match-start100-short-ign\"),\n",
    "                    (\"sperc\",\"wt1-pri2-match-ign\"),                   \n",
    "                    (\"waterfilling\", \"ideal-maxmin\")]\n",
    "\n",
    "legend_rel_pos={\"learning60\": (0.45, 0.05), \"learning80\": (0.45, 0.05),\\\n",
    "               \"search60\": (0.35, 1.52), \"search80\": (0.60, 1.48)}\n",
    "\n",
    "buckets_by_cdf = {\n",
    "    \"search\": [0.01, 0.33, 0.66, 1.0],\n",
    "    \"learning\": [0.01, 1.0]\n",
    "}\n",
    "\n",
    "def get_styles(filename):\n",
    "    \"\"\"\n",
    "    Returns line_label, style, color, alpha for scheme, kw in filename\n",
    "    \"\"\"\n",
    "    c = get_config(filename)\n",
    "    scheme, kw = c[\"scheme\"], c[\"kw\"]\n",
    "    return styles[scheme][kw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# assuming spine-leaf topology\n",
    "def flow_rtt(gid):\n",
    "    src_tor, dst_tor = [int(int(host)/16) for host in gid.split(\"-\")]\n",
    "    if src_tor == dst_tor:\n",
    "        return 10.8e-6\n",
    "    return 11.6e-6\n",
    "\n",
    "def fct_file_to_df(filename):\n",
    "    config = get_config(filename)\n",
    "    \n",
    "    print(\", \".join([\"%s: %s\" % (key, config[key]) for key in \n",
    "                                     [\"cdf\", \"load\", \"topo\", \"servers\",\n",
    "                                     \"scheme\", \"kw\", \"date\"]]))\n",
    "    load = int(float(config[\"load\"])*100)\n",
    "    \n",
    "    if config[\"scheme\"] == \"waterfilling\":\n",
    "        df = pd.read_csv(filename, delim_whitespace=True, header=None,\\\n",
    "                        names=[\"fid_\", \"fid\", \"end_time_\", \"end_time\",\\\n",
    "                               \"start_time_\", \"start_time\", \"fldur_\", \"fldur\",\\\n",
    "                               \"bytes_\", \"bytes\", \"tmp_pkts_\", \"tmp_pkts\",\\\n",
    "                               \"gid_\", \"gid\"])\n",
    "        \n",
    "\n",
    "        df.bytes = (df.bytes/1500)*1460\n",
    "        df[\"fldur_data\"] = df.fldur + df[\"gid\"].map(flow_rtt)\n",
    "    else:\n",
    "        df = pd.read_csv(filename, delim_whitespace=True, header=None,\\\n",
    "                            names=[\"flow_stats\", \"flow_end\", \"gid_\", \"gid\",\\\n",
    "                                    \"start_time_\", \"start_time\", \"pid_\", \"pid\",\\\n",
    "                                    \"fid_\", \"fid\", \"bytes_\", \"bytes\", \"fldur_\",\\\n",
    "                                      \"fldur\", \"fldur_data_\", \"fldur_data\", \"actfl_\",\\\n",
    "                                      \"actfl_\", \"bps\", \"bps_\", \"tmp_pkts_\", \"tmp_pkts\",\\\n",
    "                                       \"bytes_scheduled_\", \"bytes_scheduled\", \"bytes_sent_\", \"bytes_sent\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transfer_time(num_bytes, line_rate=100): #Gb/s\n",
    "    return (num_bytes * 8.0)/ (line_rate * 1.0e9)\n",
    "\n",
    "def augment_df(df):    \n",
    "    df[\"min_fct\"] = df[\"bytes\"].map(transfer_time) + df[\"gid\"].map(flow_rtt)\n",
    "    df[\"norm_fct\"] = df[\"fldur_data\"]/df[\"min_fct\"]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_num_flows(df, buckets, sort_key=\"bytes\"):\n",
    "    df.sort_values([sort_key], ascending=[1],inplace=True)\n",
    "    num_flows = len(df)\n",
    "    dfs = []\n",
    "    thresh = []\n",
    "    min_flow = 0\n",
    "    \n",
    "    for max_fraction in buckets:\n",
    "        max_flow = int(max_fraction * (num_flows - 1))\n",
    "        thresh.append(max_flow)\n",
    "        dfs.append(df.iloc[min_flow:max_flow,:])\n",
    "        min_flow = max_flow\n",
    "    return dfs, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_num_bytes(df, buckets, sort_key=\"bytes\"):\n",
    "    assert(len(buckets) >= 1)\n",
    "    assert(buckets[-1] == 1)\n",
    "\n",
    "    df.sort_values([sort_key], ascending=[1],inplace=True)\n",
    "    num_bytes = float(sum(df.bytes.values))\n",
    "    cumsum_bytes = np.cumsum(df.bytes.values) / num_bytes\n",
    "    \n",
    "    num_buckets = len(buckets)\n",
    "    num_flows = len(df)\n",
    "    \n",
    "    dfs = []\n",
    "    thresh = []\n",
    "    min_flow = 0\n",
    "    bucket = 0\n",
    "    for flow in range(num_flows):\n",
    "        assert(bucket < num_buckets)\n",
    "        max_fraction =  buckets[bucket]\n",
    "        if cumsum_bytes[flow] >= max_fraction:\n",
    "            thresh.append(flow)\n",
    "            dfs.append(df.iloc[min_flow:flow, :])\n",
    "            min_flow = flow\n",
    "            bucket += 1\n",
    "\n",
    "    return dfs, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fct_files:\n",
    "    print(\"%s: %s\" % (f, str(get_styles(f))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we group files by CDF, load\n",
    "files_by_cdf_load = {}\n",
    "for f in fct_files:\n",
    "    cdf = get_config(f)[\"cdf\"]\n",
    "    load = int(float(get_config(f)[\"load\"]) * 100)\n",
    "    if (cdf, load) not in files_by_cdf_load: \n",
    "        files_by_cdf_load[(cdf, load)] = []\n",
    "    files_by_cdf_load[(cdf, load)].append(f)\n",
    "\n",
    "cdf_loads = files_by_cdf_load.keys()\n",
    "print(cdf_loads)\n",
    "print(files_by_cdf_load)\n",
    "\n",
    "for cdf, load in cdf_loads:\n",
    "    files_by_cdf_load[(cdf, load)] = sorted(files_by_cdf_load[(cdf, load)], key=lambda f:\\\n",
    "         schemes_in_order.index((get_config(f)[\"scheme\"],\n",
    "                                 get_config(f)[\"kw\"])))\n",
    "    print([(get_config(f)[\"scheme\"],get_config(f)[\"kw\"])\\\n",
    "          for f in files_by_cdf_load[(cdf, load)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xticks(xmin, xmax):\n",
    "    xrange = xmax - xmin\n",
    "    print(xrange)\n",
    "    if (xrange > 40): xticks = range(xmin, xmax+1, 10)\n",
    "    elif (xrange > 20): xticks = [0, 10, 15] + list(range(xmin, xmax+1, 10))\n",
    "    else: xticks = [tick for tick in [0, 1, 2, 3, 4, 5, 10, 15, 20] if tick <= xmax]\n",
    "    print(xticks)\n",
    "    return xticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_subplots = {}\n",
    "matplotlib.use(\"TkAgg\")\n",
    "print(matplotlib.get_backend())\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "myHandlerMap = {}\n",
    "\n",
    "for cdf, load in cdf_loads:\n",
    "    buckets =  buckets_by_cdf[cdf] # by max, starting at 0.0 \n",
    "    num_buckets = len(buckets)\n",
    "    xmin = {}\n",
    "    xmax = {}\n",
    "    if num_buckets <= 2: figsize = (6,3)\n",
    "    else: figsize = None        \n",
    "    fig, ax = plt.subplots(nrows=int(math.ceil(num_buckets/2.0)), ncols=2, figsize=figsize)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for file_num, f in enumerate(files_by_cdf_load[(cdf, load)]):\n",
    "        dfs, thresh =\\\n",
    "            split_df_by_num_bytes(augment_df(fct_file_to_df(f)),\\\n",
    "                                  buckets)\n",
    "\n",
    "        line_label, style, color, alpha = get_styles(filename=f)\n",
    "        \n",
    "        for i in range(num_buckets):\n",
    "            if num_buckets <= 2: axi = ax[i]\n",
    "            else: axi = ax[int(i/2)][i%2]\n",
    "            \n",
    "                \n",
    "            norm_fct = sorted([float(fct) for fct in dfs[i].norm_fct.values])\n",
    "            cum_dist = np.linspace(0., 1., len(norm_fct))\n",
    "            \n",
    "            line = axi.plot(norm_fct, cum_dist, label=line_label,\n",
    "                            linestyle=style, color=color, alpha=alpha)\n",
    "            print(line)\n",
    "            myHandlerMap[str(line)] = HandlerLine2D()\n",
    "            if file_num == 0:\n",
    "                #print(\"file_num = %d, i = %d\" % (file_num, i))\n",
    "                min_frac = 0; min_flow = 0;\n",
    "                if i > 0: \n",
    "                    min_frac = buckets[i-1]; \n",
    "                    min_flow = thresh[i-1]\n",
    "                max_frac = buckets[i]\n",
    "                max_flow = thresh[i] \n",
    "                num_flows = len(dfs[i])\n",
    "                title = \"%.0f-%.0f%% of bytes, %.0f%% of flows\" % \\\n",
    "                (min_frac*100, max_frac*100, float(max_flow-min_flow)/num_flows)\n",
    "                \n",
    "                axi.set_title(title, fontsize=fontsize)\n",
    "                max_cdf_with_enough_samples = min(1.0, (num_flows/30.0)/100.0)\n",
    "                line = axi.axhline(y=max_cdf_with_enough_samples,\\\n",
    "                        linestyle='dashed', color='r')\n",
    "                #print(line)\n",
    "                axi.set_ylabel(\"CDF\", fontsize=fontsize, labelpad=0)\n",
    "                axi.set_xlabel(\"FCT (norm. by min. FCT)\", fontsize=fontsize)\n",
    "                xmin[i] = norm_fct[0]\n",
    "                xmax[i] = norm_fct[-1]\n",
    "            \n",
    "            xmin[i] = min(xmin[i], norm_fct[0])\n",
    "            xmax[i] = max(xmax[i], norm_fct[-1])\n",
    "            if file_num == len(files_by_cdf_load[(cdf, load)]) - 1:\n",
    "                #print(\"file_num = %d\" % file_num)\n",
    "                # round to nearest ten on left, int on right\n",
    "                xmin[i] = int(xmin[i]/10.0) * 10\n",
    "                xmax[i] = min(100, int(math.ceil(xmax[i])))\n",
    "                xmax[0] = 10\n",
    "                #print(xmin[i])\n",
    "                #print(xmax[i])\n",
    "                axi.set_xlim(xmin=xmin[i], xmax=xmax[i])\n",
    "                axi.set_ylim(ymin=0, ymax=1.0)\n",
    "                xticks = get_xticks(xmin[i], xmax[i])\n",
    "                \n",
    "                axi.set_xticks(xticks)\n",
    "                for y in [0.5, 0.999]:\n",
    "                    line = axi.axhline(y=y, linestyle='solid', color='black', alpha=0.1)\n",
    "                    #print(line)\n",
    "                for x in xticks:\n",
    "                    line = axi.axvline(x=x, linestyle='solid', color='black', alpha=0.1)\n",
    "                    #print(line)\n",
    "                    \n",
    "            # end for bucket in range(num_buckets)\n",
    "        # end for f in files_by_cdf[cdf]\n",
    "    \n",
    "    fig.subplots_adjust(hspace=.5)\n",
    "    legend=plt.legend( handler_map=myHandlerMap,\\\n",
    "                  loc=(0.5,0.0),\\\n",
    "                  bbox_to_anchor=legend_rel_pos[cdf+str(load)])\n",
    "    plt.savefig(\"maxmin-%s-%d.pdf\"%(cdf, load) , bbox_inches='tight')    \n",
    "    # end for cdf, load in cdf_loads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
